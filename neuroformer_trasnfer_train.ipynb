{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter\n",
      "CONTRASTIUVEEEEEEE False\n",
      "VISUAL: True\n",
      "PAST_STATE: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "from neuroformer.model_neuroformer import Neuroformer, NeuroformerConfig\n",
    "from neuroformer.utils import get_attr\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import (set_seed, update_object, running_jupyter, \n",
    "                                 all_device, load_config, \n",
    "                                 dict_to_object, object_to_dict, recursive_print,\n",
    "                                 create_modalities_dict)\n",
    "from neuroformer.visualize import set_plot_params\n",
    "from neuroformer.data_utils import round_n, Tokenizer, NFDataloader\n",
    "from neuroformer.datasets import load_visnav, load_V1AL\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "import wandb\n",
    "\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "from neuroformer.default_args import DefaultArgs, parse_args\n",
    "\n",
    "if running_jupyter(): # or __name__ == \"__main__\":\n",
    "    print(\"Running in Jupyter\")\n",
    "    args = DefaultArgs()\n",
    "else:\n",
    "    print(\"Running in terminal\")\n",
    "    args = parse_args()\n",
    "\n",
    "# SET SEED - VERY IMPORTANT\n",
    "set_seed(args.seed)\n",
    "\n",
    "print(f\"CONTRASTIUVEEEEEEE {args.contrastive}\")\n",
    "print(f\"VISUAL: {args.visual}\")\n",
    "print(f\"PAST_STATE: {args.past_state}\")\n",
    "\n",
    "# Use the function\n",
    "if args.config is None:\n",
    "    config_path = \"./models/predict_all_behavior/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25/mconf.yaml\"\n",
    "\n",
    "    #### THIS IS THE WEIGHTS YOU WANT TO CONTINUE TRAINING FROM\n",
    "    args.resume = \"./models/predict_all_behavior/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25/model.pt\"\n",
    "else:\n",
    "    config_path = args.config\n",
    "config = load_config(config_path)  # replace 'config.yaml' with your file path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "-- DATA --\n",
    "neuroformer/data/OneCombo3_V1AL/\n",
    "df = response\n",
    "video_stack = stimulus\n",
    "DOWNLOAD DATA URL = https://drive.google.com/drive/folders/1jNvA4f-epdpRmeG9s2E-2Sfo-pwYbjeY?usp=sharing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if args.dataset in [\"lateral\", \"medial\"]:\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_visnav(args.dataset, config, \n",
    "                           selection=config.selection if hasattr(config, \"selection\") else None)\n",
    "elif args.dataset == \"V1AL\":\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_V1AL(config)\n",
    "\n",
    "spikes = data['spikes']\n",
    "stimulus = data['stimulus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID vocab size: 2026\n",
      "dt vocab size: 9\n"
     ]
    }
   ],
   "source": [
    "window = config.window.curr\n",
    "window_prev = config.window.prev\n",
    "dt = config.resolution.dt\n",
    "\n",
    "# -------- #\n",
    "\n",
    "spikes_dict = {\n",
    "    \"ID\": data['spikes'],\n",
    "    \"Frames\": data['stimulus'],\n",
    "    \"Interval\": intervals,\n",
    "    \"dt\": config.resolution.dt,\n",
    "    \"id_block_size\": config.block_size.id,\n",
    "    \"prev_id_block_size\": config.block_size.prev_id,\n",
    "    \"frame_block_size\": config.block_size.frame,\n",
    "    \"window\": config.window.curr,\n",
    "    \"window_prev\": config.window.prev,\n",
    "    \"frame_window\": config.window.frame,\n",
    "}\n",
    "\n",
    "\"\"\" \n",
    " - see mconf.yaml \"modalities\" structure:\n",
    "\n",
    "modalities:\n",
    "  behavior:\n",
    "    n_layers: 4\n",
    "    window: 0.05\n",
    "    variables:\n",
    "      speed:\n",
    "        data: speed\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "      phi:\n",
    "        data: phi\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "      th:\n",
    "        data: th\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "\n",
    "\n",
    "Modalities: any additional modalities other than spikes and frames\n",
    "    Behavior: the name of the <modality type>\n",
    "        Variables: the name of the <modality>\n",
    "            Data: the data of the <modality> in shape (n_samples, n_features)\n",
    "            dt: the time resolution of the <modality>, used to index n_samples\n",
    "            Predict: whether to predict this modality or not.\n",
    "                     If you set predict to false, then it will \n",
    "                     not be used as an input in the model,\n",
    "                     but rather to be predicted as an output. \n",
    "            Objective: regression or classification\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "frames = {'feats': stimulus, 'callback': callback, 'window': config.window.frame, 'dt': config.resolution.dt}\n",
    "\n",
    "\n",
    "def configure_token_types(config, modalities):\n",
    "    max_window = max(config.window.curr, config.window.prev)\n",
    "    dt_range = math.ceil(max_window / dt) + 1\n",
    "    n_dt = [round_n(x, dt) for x in np.arange(0, max_window + dt, dt)]\n",
    "\n",
    "    token_types = {\n",
    "        'ID': {'tokens': list(np.arange(0, data['spikes'].shape[0] if isinstance(data['spikes'], np.ndarray) \\\n",
    "                                    else data['spikes'][1].shape[0]))},\n",
    "        'dt': {'tokens': n_dt, 'resolution': dt},\n",
    "        **({\n",
    "            modality: {\n",
    "                'tokens': sorted(list(set(eval(modality)))),\n",
    "                'resolution': details.get('resolution')\n",
    "            }\n",
    "            # if we have to classify the modality, \n",
    "            # then we need to tokenize it\n",
    "            for modality, details in modalities.items() if config.modalities is not None\n",
    "            if details.get('predict', False) and details.get('objective', '') == 'classification'\n",
    "        } if modalities is not None else {})\n",
    "    }\n",
    "    return token_types\n",
    "\n",
    "modalities = create_modalities_dict(data, config.modalities) if get_attr(config, 'modalities', None) else None\n",
    "token_types = configure_token_types(config, modalities)\n",
    "tokenizer = Tokenizer(token_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_layers 4\n",
      "variables {'speed': {'data': array([ 0.03216422, -0.08701274, -0.36626688, ..., -0.657169  ,\n",
      "       -0.79575145, -0.97988075], dtype=float32), 'dt': 0.05, 'window': 0.05, 'predict': True, 'objective': 'regression'}, 'phi': {'data': array([2.15574538, 2.15574538, 3.4186857 , ..., 0.20013816, 0.18952116,\n",
      "       0.18952116]), 'dt': 0.05, 'window': 0.05, 'predict': True, 'objective': 'regression'}, 'th': {'data': array([0.50604788, 0.50604788, 0.39550107, ..., 1.84192663, 1.7470296 ,\n",
      "       1.7470296 ]), 'dt': 0.05, 'window': 0.05, 'predict': True, 'objective': 'regression'}}\n"
     ]
    }
   ],
   "source": [
    "if modalities is not None:\n",
    "    for modality_type, modality in modalities.items():\n",
    "        for variable_type, variable in modality.items():\n",
    "            print(variable_type, variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Interval: 0.1\n",
      "Intervals:  24092\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  2026\n",
      "ID Population Size:  2026\n",
      "DT Population Size:  9\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.1\n",
      "Intervals:  24092\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  2026\n",
      "ID Population Size:  2026\n",
      "DT Population Size:  9\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.1\n",
      "Intervals:  240\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  2026\n",
      "ID Population Size:  2026\n",
      "DT Population Size:  9\n",
      "Using explicitly passed intervals\n",
      "tensor([2023, 1223, 1368, 1321, 1343,    1,  108,  625, 1321, 1321, 1321,  732,\n",
      "        1321, 1338,  121,  199, 1321, 1853, 2024, 2025, 2025, 2025, 2025, 2025,\n",
      "        2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025,\n",
      "        2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025,\n",
      "        2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025,\n",
      "        2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025,\n",
      "        2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025,\n",
      "        2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025,\n",
      "        2025, 2025, 2025, 2025])\n",
      "tensor([0., 0., 0., 1., 1., 2., 2., 2., 2., 2., 2., 3., 3., 3., 4., 4., 4., 4.,\n",
      "        7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8.])\n",
      "id_prev torch.Size([700]) torch.int64\n",
      "dt_prev torch.Size([700]) torch.float32\n",
      "pad_prev torch.Size([]) torch.int64\n",
      "id torch.Size([100]) torch.int64\n",
      "dt torch.Size([100]) torch.float32\n",
      "pad torch.Size([]) torch.int64\n",
      "interval torch.Size([]) torch.float32\n",
      "trial torch.Size([]) torch.int64\n",
      "frames torch.Size([1, 3, 30, 100]) torch.float32\n",
      "cid torch.Size([2]) torch.float32\n",
      "pid torch.Size([2]) torch.float32\n",
      "256 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2024 22:11:18 - INFO - neuroformer.model_neuroformer -   number of parameters: 2.820302e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id torch.Size([2, 100]) torch.int64\n",
      "dt torch.Size([2, 100]) torch.int64\n",
      "modalities_behavior_phi_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_phi_dt torch.Size([2]) torch.float32\n",
      "modalities_behavior_speed_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_speed_dt torch.Size([2]) torch.float32\n",
      "modalities_behavior_th_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_th_dt torch.Size([2]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                             frames=frames, intervals=train_intervals, modalities=modalities)\n",
    "test_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                            frames=frames, intervals=test_intervals, modalities=modalities)\n",
    "finetune_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                                frames=frames, intervals=finetune_intervals, modalities=modalities)\n",
    "\n",
    "    \n",
    "# print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "iterable = iter(train_dataset)\n",
    "x, y = next(iterable)\n",
    "print(x['id'])\n",
    "print(x['dt'])\n",
    "recursive_print(x)\n",
    "\n",
    "# Update the config\n",
    "config.id_vocab_size = tokenizer.ID_vocab_size\n",
    "model = Neuroformer(config, tokenizer)\n",
    "\n",
    "# Create a DataLoader\n",
    "loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "iterable = iter(loader)\n",
    "x, y = next(iterable)\n",
    "recursive_print(y)\n",
    "preds, features, loss = model(x, y)\n",
    "\n",
    "# Set training parameters\n",
    "MAX_EPOCHS = 250\n",
    "BATCH_SIZE = 32 * 5\n",
    "SHUFFLE = True\n",
    "\n",
    "if config.gru_only:\n",
    "    model_name = \"GRU\"\n",
    "elif config.mlp_only:\n",
    "    model_name = \"MLP\"\n",
    "elif config.gru2_only:\n",
    "    model_name = \"GRU_2.0\"\n",
    "else:\n",
    "    model_name = \"Neuroformer\"\n",
    "\n",
    "CKPT_PATH = f\"./models/NF.15/Visnav_VR_Expt/{args.dataset}/{model_name}/{args.title}/{str(config.layers)}/{args.seed}\"\n",
    "CKPT_PATH = CKPT_PATH.replace(\"namespace\", \"\").replace(\" \", \"_\")\n",
    "\n",
    "if os.path.exists(CKPT_PATH):\n",
    "    counter = 1\n",
    "    print(f\"CKPT_PATH {CKPT_PATH} exists!\")\n",
    "    while os.path.exists(CKPT_PATH + f\"_{counter}\"):\n",
    "        counter += 1\n",
    "\n",
    "if args.resume is not None:\n",
    "    model.load_state_dict(torch.load(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2026, 256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tok_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neuroformer(\n",
       "  (tok_emb): Embedding(2026, 256)\n",
       "  (temp_emb): LearntTemporalEmbedding(\n",
       "    (temp_emb): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (temp_emb_prev): LearntTemporalEmbedding(\n",
       "    (temp_emb): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (modality_embeddings): ModuleDict(\n",
       "    (behavior): ModuleDict(\n",
       "      (phi): ModuleDict(\n",
       "        (mlp): ProjectNorm(\n",
       "          (ln): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=1, out_features=2, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=2, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (temp_emb): TemporalEmbedding(\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (speed): ModuleDict(\n",
       "        (mlp): ProjectNorm(\n",
       "          (ln): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=1, out_features=2, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=2, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (temp_emb): TemporalEmbedding(\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (th): ModuleDict(\n",
       "        (mlp): ProjectNorm(\n",
       "          (ln): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=1, out_features=2, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=2, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (temp_emb): TemporalEmbedding(\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (pos_emb): PositionalEncoding2D()\n",
       "    )\n",
       "  )\n",
       "  (modality_projection_heads): ModuleDict(\n",
       "    (behavior): ModuleDict(\n",
       "      (phi): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (speed): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (th): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (frame_3d_emb): PositionalEncoding3D()\n",
       "  (id_drop): Dropout(p=0.2, inplace=False)\n",
       "  (im_drop): Dropout(p=0.2, inplace=False)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (video_encoder): VideoEncoder(\n",
       "    (conv_block): Sequential(\n",
       "      (0): Conv3d(1, 256, kernel_size=(3, 5, 5), stride=(3, 5, 5))\n",
       "      (1): Rearrange('b e t h w -> b t h w e')\n",
       "      (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (feature_encoder): FeatureEncoder(\n",
       "    (neural_state_blocks): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.2, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (frame_state_blocks): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.2, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neural_visual_transformer): MultimodalTransformer(\n",
       "    (modalities_blocks): ModuleDict(\n",
       "      (behavior): ModuleList(\n",
       "        (0-3): 4 x Block(\n",
       "          (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "            (resid_drop): Dropout(p=0.2, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neural_state_blocks): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.2, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (neural_state_history_blocks): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.2, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (neural_state_stimulus_blocks): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.2, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head_id): Linear(in_features=256, out_features=2026, bias=False)\n",
       "  (head_dt): Linear(in_features=256, out_features=9, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded from ./models/predict_all_behavior/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25/model.pt, omitting modules: tok_emb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Here's how to load all weights except\n",
    "for the token embeddings!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from neuroformer.utils import load_pretrained_weights\n",
    "\n",
    "if args.resume is not None:\n",
    "    load_pretrained_weights(model, args.resume,\n",
    "                            omit_modules='tok_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if args.sweep_id is not None:\n",
    "    # this is for hyperparameter sweeps\n",
    "    from neuroformer.hparam_sweep import train_sweep\n",
    "    print(f\"-- SWEEP_ID -- {args.sweep_id}\")\n",
    "    wandb.agent(args.sweep_id, function=train_sweep)\n",
    "else:\n",
    "    # Create a TrainerConfig and Trainer\n",
    "    tconf = TrainerConfig(max_epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, learning_rate=1e-4, \n",
    "                          num_workers=16, lr_decay=True, patience=3, warmup_tokens=8e7, \n",
    "                          decay_weights=True, weight_decay=1.0, shuffle=SHUFFLE,\n",
    "                          final_tokens=len(train_dataset)*(config.block_size.id) * (MAX_EPOCHS),\n",
    "                          clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                          show_grads=False,\n",
    "                          ckpt_path=CKPT_PATH, no_pbar=False, \n",
    "                          dist=args.dist, save_every=0, eval_every=5, min_eval_epoch=50,\n",
    "                          use_wandb=True, wandb_project=\"neuroformer\", \n",
    "                          wandb_group=f\"1.5.1_visnav_{args.dataset}\", wandb_name=args.title)\n",
    "\n",
    "    trainer = Trainer(model, train_dataset, test_dataset, tconf, config)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
