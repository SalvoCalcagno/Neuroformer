{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/antonis/.conda/envs/neuroformer_clean/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter\n",
      "CONTRASTIUVEEEEEEE False\n",
      "VISUAL: True\n",
      "PAST_STATE: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "from neuroformer.model_neuroformer import Neuroformer, NeuroformerConfig\n",
    "from neuroformer.utils import get_attr\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import (set_seed, update_object, running_jupyter, \n",
    "                                 all_device, load_config, \n",
    "                                 dict_to_object, object_to_dict, recursive_print,\n",
    "                                 create_modalities_dict)\n",
    "from neuroformer.visualize import set_plot_params\n",
    "from neuroformer.data_utils import round_n, Tokenizer, NFDataloader\n",
    "from neuroformer.datasets import load_visnav, load_V1AL\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "import wandb\n",
    "\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "from neuroformer.default_args import DefaultArgs, parse_args\n",
    "\n",
    "if running_jupyter(): # or __name__ == \"__main__\":\n",
    "    print(\"Running in Jupyter\")\n",
    "    args = DefaultArgs()\n",
    "else:\n",
    "    print(\"Running in terminal\")\n",
    "    args = parse_args()\n",
    "\n",
    "# SET SEED - VERY IMPORTANT\n",
    "set_seed(args.seed)\n",
    "\n",
    "print(f\"CONTRASTIUVEEEEEEE {args.contrastive}\")\n",
    "print(f\"VISUAL: {args.visual}\")\n",
    "print(f\"PAST_STATE: {args.past_state}\")\n",
    "\n",
    "# Use the function\n",
    "if args.config is None:\n",
    "    config_path = \"./models/NF.15/Visnav_VR_Expt/lateral/Neuroformer/predict_all/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25/mconf.yaml\"\n",
    "\n",
    "    #### THIS IS THE WEIGHTS YOU WANT TO CONTINUE TRAINING FROM\n",
    "    args.resume = \"./models/NF.15/Visnav_VR_Expt/lateral/Neuroformer/predict_all/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25/model.pt\"\n",
    "else:\n",
    "    config_path = args.config\n",
    "config = load_config(config_path)  # replace 'config.yaml' with your file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "-- DATA --\n",
    "neuroformer/data/OneCombo3_V1AL/\n",
    "df = response\n",
    "video_stack = stimulus\n",
    "DOWNLOAD DATA URL = https://drive.google.com/drive/folders/1jNvA4f-epdpRmeG9s2E-2Sfo-pwYbjeY?usp=sharing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if args.dataset in [\"lateral\", \"medial\"]:\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_visnav(args.dataset, config, \n",
    "                           selection=config.selection if hasattr(config, \"selection\") else None)\n",
    "elif args.dataset == \"V1AL\":\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_V1AL(config)\n",
    "\n",
    "spikes = data['spikes']\n",
    "stimulus = data['stimulus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID vocab size: 2026\n",
      "dt vocab size: 9\n"
     ]
    }
   ],
   "source": [
    "window = config.window.curr\n",
    "window_prev = config.window.prev\n",
    "dt = config.resolution.dt\n",
    "\n",
    "# -------- #\n",
    "\n",
    "spikes_dict = {\n",
    "    \"ID\": data['spikes'],\n",
    "    \"Frames\": data['stimulus'],\n",
    "    \"Interval\": intervals,\n",
    "    \"dt\": config.resolution.dt,\n",
    "    \"id_block_size\": config.block_size.id,\n",
    "    \"prev_id_block_size\": config.block_size.prev_id,\n",
    "    \"frame_block_size\": config.block_size.frame,\n",
    "    \"window\": config.window.curr,\n",
    "    \"window_prev\": config.window.prev,\n",
    "    \"frame_window\": config.window.frame,\n",
    "}\n",
    "\n",
    "\"\"\" \n",
    " - see mconf.yaml \"modalities\" structure:\n",
    "\n",
    "modalities:\n",
    "  behavior:\n",
    "    n_layers: 4\n",
    "    window: 0.05\n",
    "    variables:\n",
    "      speed:\n",
    "        data: speed\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "      phi:\n",
    "        data: phi\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "      th:\n",
    "        data: th\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "\n",
    "\n",
    "Modalities: any additional modalities other than spikes and frames\n",
    "    Behavior: the name of the <modality type>\n",
    "        Variables: the name of the <modality>\n",
    "            Data: the data of the <modality> in shape (n_samples, n_features)\n",
    "            dt: the time resolution of the <modality>, used to index n_samples\n",
    "            Predict: whether to predict this modality or not.\n",
    "                     If you set predict to false, then it will \n",
    "                     not be used as an input in the model,\n",
    "                     but rather to be predicted as an output. \n",
    "            Objective: regression or classification\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "frames = {'feats': stimulus, 'callback': callback, 'window': config.window.frame, 'dt': config.resolution.dt}\n",
    "\n",
    "  \n",
    "def configure_token_types(config, modalities, data):\n",
    "    max_window = max(config.window.curr, config.window.prev)\n",
    "    dt_range = math.ceil(max_window / config.resolution.dt) + 1\n",
    "\n",
    "    def round_n(x, resolution):\n",
    "        return round(x, int(-math.log10(resolution)))\n",
    "\n",
    "    n_dt = [round_n(x, config.resolution.dt) for x in np.arange(0, max_window + config.resolution.dt, config.resolution.dt)]\n",
    "\n",
    "    token_types = {\n",
    "        'ID': {\n",
    "            'tokens': list(np.arange(0, data['spikes'].shape[0] if isinstance(data['spikes'], np.ndarray) else data['spikes'][1].shape[0]))\n",
    "        },\n",
    "        'dt': {\n",
    "            'tokens': n_dt,\n",
    "            'resolution': config.resolution.dt\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if modalities is not None and config.modalities is not None:\n",
    "        for modality, details in modalities.items():\n",
    "            if details.get('predict', False) and details.get('objective', '') == 'classification':\n",
    "                token_types[modality] = {\n",
    "                    'tokens': sorted(list(set(eval(modality)))),\n",
    "                    'resolution': details.get('resolution')\n",
    "                }\n",
    "\n",
    "    return token_types\n",
    "\n",
    "modalities = create_modalities_dict(data, config.modalities) if get_attr(config, 'modalities', None) else None\n",
    "token_types = configure_token_types(config, modalities, data)\n",
    "tokenizer = Tokenizer(token_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_layers 4\n",
      "variables {'phi': {'data': array([2.15574538, 2.15574538, 3.4186857 , ..., 0.20013816, 0.18952116,\n",
      "       0.18952116]), 'dt': 0.05, 'window': 0.05, 'predict': True, 'objective': 'regression'}, 'speed': {'data': array([ 0.03216422, -0.08701274, -0.36626688, ..., -0.657169  ,\n",
      "       -0.79575145, -0.97988075], dtype=float32), 'dt': 0.05, 'window': 0.05, 'predict': True, 'objective': 'regression'}, 'th': {'data': array([0.50604788, 0.50604788, 0.39550107, ..., 1.84192663, 1.7470296 ,\n",
      "       1.7470296 ]), 'dt': 0.05, 'window': 0.05, 'predict': True, 'objective': 'regression'}}\n"
     ]
    }
   ],
   "source": [
    "if modalities is not None:\n",
    "    for modality_type, modality in modalities.items():\n",
    "        for variable_type, variable in modality.items():\n",
    "            print(variable_type, variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Interval: 0.1\n",
      "Intervals:  24092\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  202204\n",
      "ID Population Size:  202204\n",
      "DT Population Size:  9\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.1\n",
      "Intervals:  24092\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  202204\n",
      "ID Population Size:  202204\n",
      "DT Population Size:  9\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.1\n",
      "Intervals:  240\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  202204\n",
      "ID Population Size:  202204\n",
      "DT Population Size:  9\n",
      "Using explicitly passed intervals\n",
      "tensor([202201, 122300, 136800, 132100, 134300,    100,  10800,  62500, 132100,\n",
      "        132100, 132100,  73200, 132100, 133800,  12100,  19900, 132100, 185300,\n",
      "        202202, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203, 202203,\n",
      "        202203])\n",
      "tensor([0., 0., 0., 1., 1., 2., 2., 2., 2., 2., 2., 3., 3., 3., 4., 4., 4., 4.,\n",
      "        7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "        8., 8., 8., 8., 8., 8., 8., 8., 8., 8.])\n",
      "id_prev torch.Size([700]) torch.int64\n",
      "dt_prev torch.Size([700]) torch.float32\n",
      "pad_prev torch.Size([]) torch.int64\n",
      "id torch.Size([100]) torch.int64\n",
      "dt torch.Size([100]) torch.float32\n",
      "pad torch.Size([]) torch.int64\n",
      "interval torch.Size([]) torch.float32\n",
      "trial torch.Size([]) torch.int64\n",
      "frames torch.Size([1, 3, 30, 100]) torch.float32\n",
      "cid torch.Size([2]) torch.float32\n",
      "pid torch.Size([2]) torch.float32\n",
      "256 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/23/2024 12:24:32 - INFO - neuroformer.model_neuroformer -   number of parameters: 1.306942e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id torch.Size([2, 100]) torch.int64\n",
      "dt torch.Size([2, 100]) torch.int64\n",
      "modalities_behavior_phi_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_phi_dt torch.Size([2]) torch.float32\n",
      "modalities_behavior_speed_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_speed_dt torch.Size([2]) torch.float32\n",
      "modalities_behavior_th_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_th_dt torch.Size([2]) torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Neuroformer:\n\tsize mismatch for tok_emb.weight: copying a param with shape torch.Size([2026, 256]) from checkpoint, the shape in current model is torch.Size([202204, 256]).\n\tsize mismatch for head_id.weight: copying a param with shape torch.Size([2026, 256]) from checkpoint, the shape in current model is torch.Size([202204, 256]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mresume \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Neuroformer:\n\tsize mismatch for tok_emb.weight: copying a param with shape torch.Size([2026, 256]) from checkpoint, the shape in current model is torch.Size([202204, 256]).\n\tsize mismatch for head_id.weight: copying a param with shape torch.Size([2026, 256]) from checkpoint, the shape in current model is torch.Size([202204, 256])."
     ]
    }
   ],
   "source": [
    "train_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                             frames=frames, intervals=train_intervals, modalities=modalities)\n",
    "test_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                            frames=frames, intervals=test_intervals, modalities=modalities)\n",
    "finetune_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                                frames=frames, intervals=finetune_intervals, modalities=modalities)\n",
    "\n",
    "    \n",
    "# print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "iterable = iter(train_dataset)\n",
    "x, y = next(iterable)\n",
    "print(x['id'])\n",
    "print(x['dt'])\n",
    "recursive_print(x)\n",
    "\n",
    "# Update the config\n",
    "config.id_vocab_size = tokenizer.ID_vocab_size\n",
    "model = Neuroformer(config, tokenizer)\n",
    "\n",
    "# Create a DataLoader\n",
    "loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "iterable = iter(loader)\n",
    "x, y = next(iterable)\n",
    "recursive_print(y)\n",
    "preds, features, loss = model(x, y)\n",
    "\n",
    "# Set training parameters\n",
    "MAX_EPOCHS = 250\n",
    "BATCH_SIZE = 32 * 5\n",
    "SHUFFLE = True\n",
    "\n",
    "if config.gru_only:\n",
    "    model_name = \"GRU\"\n",
    "elif config.mlp_only:\n",
    "    model_name = \"MLP\"\n",
    "elif config.gru2_only:\n",
    "    model_name = \"GRU_2.0\"\n",
    "else:\n",
    "    model_name = \"Neuroformer\"\n",
    "\n",
    "CKPT_PATH = f\"./models/NF.15/Visnav_VR_Expt/{args.dataset}/{model_name}/{args.title}/{str(config.layers)}/{args.seed}\"\n",
    "CKPT_PATH = CKPT_PATH.replace(\"namespace\", \"\").replace(\" \", \"_\")\n",
    "\n",
    "if os.path.exists(CKPT_PATH):\n",
    "    counter = 1\n",
    "    print(f\"CKPT_PATH {CKPT_PATH} exists!\")\n",
    "    while os.path.exists(CKPT_PATH + f\"_{counter}\"):\n",
    "        counter += 1\n",
    "\n",
    "if args.resume is not None:\n",
    "    model.load_state_dict(torch.load(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded from ./models/predict_all_behavior/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25/model.pt, omitting modules: tok_emb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Here's how to load all weights except\n",
    "for the token embeddings!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from neuroformer.utils import load_pretrained_weights\n",
    "\n",
    "if args.resume is not None:\n",
    "    load_pretrained_weights(model, args.resume,\n",
    "                            omit_modules='tok_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.sweep_id is not None:\n",
    "    # this is for hyperparameter sweeps\n",
    "    from neuroformer.hparam_sweep import train_sweep\n",
    "    print(f\"-- SWEEP_ID -- {args.sweep_id}\")\n",
    "    wandb.agent(args.sweep_id, function=train_sweep)\n",
    "else:\n",
    "    # Create a TrainerConfig and Trainer\n",
    "    tconf = TrainerConfig(max_epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, learning_rate=1e-4, \n",
    "                          num_workers=16, lr_decay=True, patience=3, warmup_tokens=8e7, \n",
    "                          decay_weights=True, weight_decay=1.0, shuffle=SHUFFLE,\n",
    "                          final_tokens=len(train_dataset)*(config.block_size.id) * (MAX_EPOCHS),\n",
    "                          clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                          show_grads=False,\n",
    "                          ckpt_path=CKPT_PATH, no_pbar=False, \n",
    "                          dist=args.dist, save_every=0, eval_every=5, min_eval_epoch=50,\n",
    "                          use_wandb=True, wandb_project=\"neuroformer\", \n",
    "                          wandb_group=f\"1.5.1_visnav_{args.dataset}\", wandb_name=args.title)\n",
    "\n",
    "    trainer = Trainer(model, train_dataset, test_dataset, tconf, config)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
